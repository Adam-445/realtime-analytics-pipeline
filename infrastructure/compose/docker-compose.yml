services:
  # Kafka infrastructure
  zoo1:
    image: confluentinc/cp-zookeeper:7.8.0
    hostname: zoo1
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zoo1:2888:3888
    healthcheck:
      test: [ "CMD", "zcsh", "echo ruok | nc localhost 2181 | grep imok" ]
      interval: 5s
      timeout: 3s
      retries: 5
    networks:
      - analytics_net
    restart: unless-stopped

  kafka1:
    image: confluentinc/cp-kafka:7.8.0
    hostname: kafka1
    ports:
      - "9092:9092"
      - "29092:29092"
      - "9999:9999"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_JMX_PORT: 9999
      KAFKA_JMX_HOSTNAME: ${DOCKER_HOST_IP:-127.0.0.1}
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
    depends_on:
      - zoo1
    healthcheck:
      test: [ "CMD", "bash", "-c", "echo > /dev/tcp/localhost/9092" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - analytics_net
    restart: unless-stopped

  # Flink Infrastructure
  jobmanager:
    build:
      context: ../../services/processing
      dockerfile: Dockerfile.flink
    hostname: jobmanager
    ports:
      - "8081:8081"
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: jobmanager
        jobmanager.memory.process.size: 1600m
    command: jobmanager
    networks:
      - analytics_net
  
  taskmanager1:
    build:
      context: ../../services/processing
      dockerfile: Dockerfile.flink
    hostname: taskmanager1
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: jobmanager
        taskmanager.memory.process.size: 1728m
        taskmanager.numberOfTaskSlots: 2
    depends_on:
      - jobmanager
    command: taskmanager
    networks:
      - analytics_net

  taskmanager2:
    build:
      context: ../../services/processing
      dockerfile: Dockerfile.flink
    hostname: taskmanager2
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: jobmanager
        taskmanager.memory.process.size: 1728m
        taskmanager.numberOfTaskSlots: 2
    depends_on:
      - jobmanager
    command: taskmanager
    networks:
      - analytics_net

  clickhouse:
    image: clickhouse/clickhouse-server:25.6
    hostname: clickhouse
    ports:
      - "8123:8123"  # HTTP API
      - "9000:9000"  # Native protocol
    volumes:
      - clickhouse_data:/var/lib/clickhouse
    environment:
      CLICKHOUSE_DB: analytics
      CLICKHOUSE_USER: admin
      CLICKHOUSE_PASSWORD: admin
    networks:
      - analytics_net

  # Services
  ingestion:
    build:
      context: ../../services/ingestion
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    depends_on:
      - kafka1
    networks:
      - analytics_net
    restart: on-failure

  processing:
    build:
      context: ../../services/processing
      dockerfile: Dockerfile.processing
    environment:
      FLINK_PROPERTIES: "jobmanager.rpc.address: jobmanager"
    depends_on:
      - kafka1
      - jobmanager
      - taskmanager1
    networks:
      - analytics_net
    restart: on-failure
    command: [ "bash", "/app/bin/entrypoint.sh" ]

  storage:
    build:
      context: ../../services/storage
      dockerfile: Dockerfile
    depends_on:
      - clickhouse
      - kafka1
    volumes:
      - ../../services/storage/src:/app/src:ro
    networks:
      - analytics_net
    restart: unless-stopped
      
volumes:
  clickhouse_data:

networks:
  analytics_net:
    driver: bridge
    name: analytics_net